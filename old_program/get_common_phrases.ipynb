{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Kategori isimlerini ve karşılık gelen category_key değerlerini içeren bir sözlük\n",
    "category_names = {\n",
    "    1: \"Common expressions\",\n",
    "    2: \"Greetings\",\n",
    "    3: \"Travel, directions\",\n",
    "    4: \"Numbers and money\",\n",
    "    5: \"Location\",\n",
    "    6: \"Phone/internet/mail\",\n",
    "    7: \"Time and dates\",\n",
    "    8: \"Accommodations\",\n",
    "    9: \"Dining\",\n",
    "    10: \"Making friends\",\n",
    "    11: \"Entertainment\",\n",
    "    12: \"Shopping\",\n",
    "    13: \"Communication difficulties\",\n",
    "    14: \"Emergency and health\",\n",
    "    15: \"Cultural expressions/terms\",\n",
    "    16: \"General questions\",\n",
    "    17: \"Work\",\n",
    "    18: \"Weather\",\n",
    "    19: \"Verbs\",\n",
    "    20: \"Miscellaneous\"\n",
    "}\n",
    "\n",
    "def scrape_data(category_key, category_name):\n",
    "    # Send a GET request to the website\n",
    "    url = f\"https://www.englishspeak.com/en/english-phrases?category_key={category_key}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the elements containing the data you want to scrape\n",
    "    data_elements = soup.select('p.test')\n",
    "\n",
    "    # Extract the data from the elements\n",
    "    data = []\n",
    "\n",
    "    for element in data_elements:\n",
    "        text = ' '.join([item.strip() for item in element.stripped_strings])\n",
    "        data.append(text)\n",
    "\n",
    "    # Return data along with the category name\n",
    "    return [(category_name, item) for item in data]\n",
    "\n",
    "# Kategori isimlerini category_key'e göre sırala\n",
    "sorted_categories = sorted(category_names.items(), key=lambda x: x[0])\n",
    "\n",
    "# Tüm verileri tutacak olan liste\n",
    "all_data = []\n",
    "\n",
    "# Her kategoriyi sıralı olarak işle\n",
    "for category_key, category_name in sorted_categories:\n",
    "    category_data = scrape_data(category_key, category_name)\n",
    "    all_data.extend(category_data)\n",
    "\n",
    "# DataFrame oluştur\n",
    "df = pd.DataFrame(all_data, columns=['Category', 'Phrase'])\n",
    "\n",
    "# CSV dosyasına verileri yaz\n",
    "df.to_csv('english_phrases.csv', index=False, encoding='utf-8', sep=',')\n",
    "\n",
    "print(\"Data saved to english_phrases.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('english_phrases.txt', index=False,sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
